{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import localizer\n",
    "from localizer import models, keras_helpers, util, visualization\n",
    "from localizer.localizer import Localizer\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread\n",
    "from os.path import join\n",
    "import os\n",
    "from pylab import rcParams\n",
    "import h5py\n",
    "import keras\n",
    "import numpy as np\n",
    "rcParams['figure.figsize'] = 15, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/ben/deeplocalizer_data/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc = Localizer(data_dir, load_filter_network = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, X_val, y_val = util.load_or_restore_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtersize = (16, 16)\n",
    "Xs_train = util.resize_data(X_train, filtersize)\n",
    "Xs_val   = util.resize_data(X_val, filtersize)\n",
    "Xs_test  = util.resize_data(X_test, filtersize)\n",
    "\n",
    "print(Xs_train.shape)\n",
    "print(Xs_test.shape)\n",
    "print(Xs_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saliency_datagen = keras_helpers.get_datagen(Xs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ys_out = keras_helpers.predict_model(loc.saliency_network, Xs_test, saliency_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precision, recall, average_precision, thresholds, fpr, tpr, roc_auc = keras_helpers.evaluate_model(\n",
    "    y_test > 0.75, ys_out, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saliency_threshold = keras_helpers.select_threshold(precision, recall, thresholds, min_value=0.90, optimize='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beesbook_dir = \"/home/beesbook/beesbook-data\"\n",
    "beesbook_2015 =  join(beesbook_dir, \"season_2015_preprocces\")\n",
    "with open(join(beesbook_2015, \"images.txt\")) as f:\n",
    "    beesbook_images = [l.rstrip('\\n') for l in f.readlines()]\n",
    "    \n",
    "beesbook_tag_dir = join(beesbook_dir, \"season_2015_tags\")\n",
    "os.makedirs(beesbook_tag_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5_fname = join(beesbook_tag_dir, \"tags.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_samples = 1024\n",
    "nb_chunks=1024\n",
    "h5file = h5py.File(h5_fname)\n",
    "tags = h5file.create_dataset(\"tags\", shape=(init_samples, 1, 64, 64), \n",
    "                             maxshape=(None, 1, 64, 64), \n",
    "                             chunks=(nb_chunks, 1, 64, 64), \n",
    "                             dtype='float32')\n",
    "saliency_dset = h5file.create_dataset(\"saliency\", shape=(init_samples,), \n",
    "                                      maxshape=(None,), chunks=(2048,), \n",
    "                                      dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "progbar = keras.utils.generic_utils.Progbar(len(beesbook_images))\n",
    "nb_tags = 0\n",
    "grow_samples = nb_chunks*10\n",
    "nb_batch_samples = 32\n",
    "batch = []\n",
    "beesbook_images = beesbook_images\n",
    "threshold = 0.99500811100006104\n",
    "for i, imfname in enumerate(beesbook_images):\n",
    "    if len(batch) == nb_batch_samples or i == len(beesbook_images):  \n",
    "        for b in batch:\n",
    "            assert len(b[0]) == len(b[1])\n",
    "        batch_sali = np.concatenate([b[0] for b in batch], axis=0)\n",
    "        batch_tags = np.concatenate([b[1] for b in batch], axis=0)\n",
    "        assert len(batch_tags) == len(batch_sali), \"{}, {}\".format(len(batch_tags), len(batch_sali))\n",
    "        \n",
    "        end = nb_tags + len(batch_tags)\n",
    "        while end >= len(tags):\n",
    "            tags.resize(len(tags) + grow_samples, axis=0)\n",
    "            saliency_dset.resize(len(saliency_dset) + grow_samples, axis=0)\n",
    "        \n",
    "        \n",
    "        indicies = np.random.shuffle(np.arange(len(batch_tags)))\n",
    "        tags[nb_tags:end] = batch_tags[indicies]\n",
    "        saliency_dset[nb_tags:end] = batch_sali[indicies]\n",
    "        nb_tags += len(batch_tags)\n",
    "        batch = []\n",
    "    \n",
    "    saliencies, candidates, rois = loc.detect_tags(imfname, threshold)\n",
    "    assert len(saliencies.reshape(-1)) == len(rois)\n",
    "    assert len(tags) == len(saliency_dset)\n",
    "    batch.append((saliencies.reshape((-1,)), rois))\n",
    "    os.remove(imfname)\n",
    "    progbar.add(1)\n",
    "    \n",
    "h5file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show(imfname, threshold):\n",
    "    saliencies, candidates, rois = loc.detect_tags(imfname, threshold)\n",
    "    print(saliencies.shape)\n",
    "    plt.imshow(visualization.get_roi_overlay(candidates, imread(imfname) / 255.))\n",
    "    plt.show()\n",
    "    \n",
    "for threshold in [0.75, 0.80, 0.85, 0.90, 0.95, 0.995]:\n",
    "    print(threshold)\n",
    "    cam1 = \"/home/ben/deeplocalizer_data/images/season_2015/cam1/Cam_1_20150911120849_847258_wb.jpeg\"\n",
    "    cam3 = \"/home/ben/deeplocalizer_data/images/season_2015/cam3/Cam_3_20150915235539_739596_wb.jpeg\"\n",
    "    show(cam1, threshold)\n",
    "    show(cam3, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = plt.imshow(visualization.get_roi_overlay(candidates, imread(imfile) / 255.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
