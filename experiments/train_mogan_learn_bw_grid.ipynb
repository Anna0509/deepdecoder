{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from beras.data_utils import HDF5Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from beras.gan import GAN\n",
    "from deepdecoder.utils import visualise_tiles, zip_visualise_tiles, np_binary_mask\n",
    "from deepdecoder.networks import dcgan_generator, dcgan_discriminator, mogan_learn_bw_grid, \\\n",
    "    dcgan_seperated_generator, dcgan_variational_add_generator\n",
    "from deepdecoder.data import gen_diff_gan, normalize_grid_params\n",
    "from deepdecoder.model_utils import add_uniform_noise, plot_weights_histogram\n",
    "from deepdecoder.grid_curriculum import get_generator_and_callback, reduced_id_lecture, exam, \\\n",
    "    z_rot_lecture, y_rot_lecture, x_rot_lecture, grid_generator\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.callbacks import Callback\n",
    "from keras.initializations import glorot_uniformt\n",
    "import pylab\n",
    "import time\n",
    "import h5py\n",
    "pylab.rcParams['figure.figsize'] = (18, 18)\n",
    "import theano\n",
    "from dotmap import DotMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_nb_out_channels = 1\n",
    "g = dcgan_variational_add_generator(nb_z=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#g_model.load_weights('g_z025_single_channel_small.hdf5')\n",
    "#add_uniform_noise(g, 0.06)\n",
    "def reinitialize_v_deconv():\n",
    "    deconv = g.layers[-2]\n",
    "    deconv_weight = deconv.get_weights()[0]\n",
    "    v_weight = deconv_weight[:, 1:]\n",
    "    print(v_weight.shape)\n",
    "    shared_weight = glorot_uniform(v_weight.shape)\n",
    "    v_weight = shared_weight.get_value()\n",
    "    del shared_weight\n",
    "    deconv_weight[:, 1:] = v_weight\n",
    "    deconv.set_weights([deconv_weight])\n",
    "    assert (deconv_weight[:, 1:] == v_weight).all()\n",
    "    \n",
    "#reinitialize_v_deconv()\n",
    "\n",
    "def add_noise_to_variation(std=0.02):\n",
    "    for name, layer in g.nodes.items():\n",
    "        if name.startswith('var'):\n",
    "            weights  = layer.get_weights()\n",
    "            for w in weights:\n",
    "                w += np.random.normal(0, std, w.shape)\n",
    "            layer.set_weights(weights)\n",
    "\n",
    "def reset_variation():\n",
    "    for name, layer in g.nodes.items():\n",
    "        if name.startswith('var'):\n",
    "            weights  = layer.get_weights()\n",
    "            for i, w in enumerate(weights):\n",
    "                shared_weight = glorot_uniform(w.shape)\n",
    "                weights[i] = shared_weight.get_value()\n",
    "                del shared_weight\n",
    "            layer.set_weights(weights)\n",
    "\n",
    "add_noise_to_variation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reset_variation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "discriminator = dcgan_discriminator()\n",
    "nb_z = 19\n",
    "optimizer = lambda: Adam(lr=0.0002, beta_1=0.5)\n",
    "mogan, grid_bw_loss_weight = mogan_learn_bw_grid(g, discriminator, optimizer, nb_z=nb_z)\n",
    "start = time.time()\n",
    "mogan.compile()\n",
    "print(\"Done Compiling in {0:.2f}s\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags_fname = '/home/leon/data/tags.hdf5'\n",
    "h5 = h5py.File(tags_fname, 'r')\n",
    "batch_size = mogan.gan.batch_size\n",
    "epoch_size = 100*batch_size\n",
    "nb_tags = h5['tags'].shape[0]\n",
    "nb_tags = (nb_tags // epoch_size)*epoch_size\n",
    "tags = HDF5Tensor(tags_fname, 'tags', 0, nb_tags)\n",
    "assert len(tags) % epoch_size == 0\n",
    "print(nb_tags // epoch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_conds(batch):\n",
    "    return {\n",
    "        'grid_idx': batch.grid_idx,\n",
    "        'z_rot90': batch.z_rot90,\n",
    "        'grid_params': batch.grid_params\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curriculum = [\n",
    "    reduced_id_lecture(0.03),\n",
    "    reduced_id_lecture(0.1),\n",
    "    reduced_id_lecture(0.5),\n",
    "    \n",
    "    reduced_id_lecture(0.5) + z_rot_lecture(0.05),\n",
    "    reduced_id_lecture(0.5) + z_rot_lecture(0.15),\n",
    "    reduced_id_lecture(0.5) + z_rot_lecture(0.25),\n",
    "    \n",
    "    reduced_id_lecture(0.5) + x_rot_lecture(0.5),\n",
    "    reduced_id_lecture(0.5) + y_rot_lecture(0.5),\n",
    "    \n",
    "    z_rot_lecture(0.25),\n",
    "    x_rot_lecture(0.5) + y_rot_lecture(0.5) + z_rot_lecture(0.25),\n",
    "    x_rot_lecture(1.) + y_rot_lecture(1.) + z_rot_lecture(0.05),\n",
    "    x_rot_lecture(1.) + y_rot_lecture(1.) + z_rot_lecture(0.25),\n",
    "]\n",
    "for c in curriculum:\n",
    "    c.pass_limit = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "samples_per_epoch=100*batch_size\n",
    "\n",
    "nb_channels = 1\n",
    "grid_raw_generator, curriculum_cb = get_generator_and_callback(curriculum, samples_per_epoch)\n",
    "draw_raw_generator = grid_generator(curriculum_cb, batch_size)\n",
    "\n",
    "def grid_generator_wrapper(input_dim=40):\n",
    "    while True:\n",
    "        params, grid_idx = next(grid_raw_generator)\n",
    "        size = len(params)\n",
    "        params = normalize_grid_params(params)\n",
    "        z_bins = np.random.choice(4, (size, 1))\n",
    "        yield DotMap({\n",
    "            'grid_params': params.astype(np.float32),\n",
    "            'grid_idx': grid_idx,\n",
    "            'z_rot90': z_bins,\n",
    "        })\n",
    "        \n",
    "def draw_generator(input_dim=40):\n",
    "    while True:\n",
    "        params, grid_idx = next(draw_raw_generator)\n",
    "        size = len(params)\n",
    "        params = normalize_grid_params(params)\n",
    "        z_bins = np.random.choice(4, (size, 1))\n",
    "        yield DotMap({\n",
    "            'grid_params': params.astype(np.float32),\n",
    "            'grid_idx': grid_idx,\n",
    "            'grid_bw': np_binary_mask(grid_idx),\n",
    "            'z_rot90': z_bins,\n",
    "        })\n",
    "        \n",
    "input_dim = 40\n",
    "generator = grid_generator_wrapper(input_dim)\n",
    "batch = next(grid_generator_wrapper(input_dim))\n",
    "params, grids = batch['grid_params'], batch['grid_idx']                \n",
    "print(params.shape)\n",
    "\n",
    "class CallbackFilterOnTrainBegin(Callback):\n",
    "    def __init__(self, cb):\n",
    "        self.cb = cb\n",
    "    def on_epoch_begin(self, epoch, log={}):\n",
    "        self.cb.on_epoch_begin(epoch, log)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, log={}):\n",
    "        self.cb.on_epoch_end(epoch, log)\n",
    "        if not self.cb.model.stop_training:\n",
    "            add_noise_to_variation(std=0.02)\n",
    "\n",
    "    def on_batch_end(self, batch, log={}):\n",
    "        if 'cond_loss' in log:\n",
    "            log['loss'] = log['cond_loss']\n",
    "        self.cb.on_batch_end(batch, log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_diff_gan():\n",
    "    batch = next(draw_generator())\n",
    "    outs = mogan.gan.debug(tags[0:batch_size], conditionals=get_conds(batch))\n",
    "    zip_visualise_tiles(outs.real, batch.grid_bw, outs.g_out[:, 0], outs.g_out[:, 1], outs.fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_diff_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_bw_loss_weight.set_value(1.0)\n",
    "# curriculum_cb.on_train_begin()\n",
    "curriculum_cb.model = mogan\n",
    "mogan.stop_training = False\n",
    "for i in range(300):\n",
    "    print(i)\n",
    "    ti = (i*epoch_size) % nb_tags\n",
    "    batch = next(generator)\n",
    "    batch['real'] = tags[ti:ti+epoch_size]\n",
    "    mogan.fit(batch, nb_epoch=1, verbose=1, callbacks=[CallbackFilterOnTrainBegin(curriculum_cb)])\n",
    "    if i % 15 == 0 or i < 15 or (i < 30 and i % 2 == 0) or (i < 50 and i % 5 == 0): \n",
    "        draw_diff_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mogan.gan.save('gan_17_1_total_sperated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
