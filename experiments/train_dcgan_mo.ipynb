{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from deepdecoder.networks import dcgan_generator, dcgan_discriminator, gan_grid_idx, mogan_pyramid\n",
    "from deepdecoder.grid_curriculum import exam, grids_from_lecture\n",
    "from deepdecoder.data import normalize_generator, grids_lecture_generator, load_real_hdf5_tags\n",
    "from deepdecoder.utils import zip_visualise_tiles, np_binary_mask, visualise_tiles\n",
    "from deepdecoder.visualise import plot_multi_objective_grads\n",
    "from beras.gan import sequential_to_gan\n",
    "from keras.optimizers import Adam\n",
    "from keras.objectives import binary_crossentropy, mse\n",
    "from keras.callbacks import Callback\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import time\n",
    "from itertools import combinations\n",
    "import seaborn\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (16, 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_batches_per_epoch = 100\n",
    "epoch_size = batch_size*num_batches_per_epoch\n",
    "nb_fake = 96\n",
    "nb_real = 36\n",
    "generator_input_dim=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = dcgan_generator(n=32, input_dim=generator_input_dim)\n",
    "d = dcgan_discriminator(n=32)\n",
    "gan = sequential_to_gan(g, d, nb_real=nb_real, nb_fake=nb_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# g.load_weights(\"generator_pyramdi_loss.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags = load_real_hdf5_tags('/mnt/storage/beesbook/season_2015_tags/tags_plain_64x64.hdf5', nb_real,  num_batches_per_epoch)\n",
    "nb_tags = len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.grid(False)\n",
    "visualise_tiles(tags[0:256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mogan = mogan_pyramid(g, d, lambda: Adam(lr=0.0002, beta_1=0.5), nb_z=31, \n",
    "                      gan_objective=binary_crossentropy,\n",
    "                      d_loss_grad_weight=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # expected loss g / wanted loss tags\n",
    "    \"cond_loss\": 12, \n",
    "    \"g_loss\": 1,\n",
    "}\n",
    "for name, weight in weights.items():\n",
    "    mogan.multi_objectives.set_objective_weight(name, weight)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "mogan.compile()\n",
    "mogan.multi_objectives.compile_get_grads()\n",
    "print(\"Done Compiling in {}s\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plt_hist(x, label, num_bins=50, **kwargs):\n",
    "    hist, bins = np.histogram(x, bins=num_bins)\n",
    "    width = 0.7 * (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    plt.bar(center, hist, align='center', width=width, label=label, alpha=0.2, **kwargs)\n",
    "\n",
    "def plot_multi_objective_grads(params, grads):                                  \n",
    "    for i, grad_dict in enumerate(grads):                                       \n",
    "        fig = plt.figure()                                                      \n",
    "        print(params[i])                                                        \n",
    "        print(i)                                                                \n",
    "        fig.add_subplot(2, 1, 2)                                                \n",
    "        plt.title(\"{} grad historgram\".format(i))                                             \n",
    "        colors = ('r', 'g', 'b')\n",
    "        for color, (name, grad) in zip(colors, grad_dict.items()):           \n",
    "            plt_hist(grad, name, color=color)   \n",
    "        plt.legend()\n",
    "        plt.show()                                                              \n",
    "        print(\"multiplication\")                                                 \n",
    "        fig.add_subplot(2, 1, 2)                                                \n",
    "        plt.title(\"{} multi histogram\".format(i))                     \n",
    "        for color, ((name_a, a), (name_b, b)) in zip(colors,                  \n",
    "             combinations(grad_dict.items(), 2)):                            \n",
    "            plt_hist(a*b, \"{}-{}\".format(name_a, name_b), color=color) \n",
    "        plt.legend()\n",
    "        plt.show()                                                                                   \n",
    "\n",
    "def plot_grads():\n",
    "    tag_batch = tags[0:batch_size]\n",
    "    params, grid_idx = next(grids_lecture_generator(batch_size))\n",
    "    inputs = [tag_batch.astype(np.float32), grid_idx.astype(np.float32), params.astype(np.float32)]\n",
    "    grads = mogan.multi_objectives.get_grads(inputs)\n",
    "    plot_multi_objective_grads(mogan.multi_objectives.params, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def should_visualise(i):\n",
    "    return i % 50 == 0 or \\\n",
    "        (i < 1000 and i % 20 == 0) or \\\n",
    "        (i < 100 and i % 5 == 0) or \\\n",
    "        i < 15\n",
    "def visualise():\n",
    "    vis_params, vis_idx = next(grids_lecture_generator(batch_size))\n",
    "    zip_visualise_tiles(np_binary_mask(vis_idx),\n",
    "                        mogan.gan.generate(conditionals={'grid_params': vis_params}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grid_generator():\n",
    "    for i, (params, grid_idx) in enumerate(grids_lecture_generator(batch_size)):\n",
    "        ti = i % nb_tags\n",
    "        tag_batch = tags[ti:ti+batch_size]\n",
    "        inputs = {'real': tag_batch, 'cond_true': grid_idx, 'grid_params': params}\n",
    "        yield inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VisualiseCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if should_visualise(epoch):\n",
    "            visualise()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(dict([(1, 3)]).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "gan = mogan.gan\n",
    "gan._compile_debug(mogan.build_dict)\n",
    "print(\"Done Compiling in {}s\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gan.debug_output(mogan.build_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(mogan.build_dict.conditionals_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PrintLossGrad(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        inputs = next(grid_generator())\n",
    "        real = inputs['real']\n",
    "        del inputs['real']\n",
    "        del inputs['cond_true']\n",
    "        print(len(inputs))\n",
    "        debug = gan.debug(real, conditionals=inputs)\n",
    "        print(\"d_loss_grad: {}\".format(float(debug.d_loss_grad)))\n",
    "        visualise_tiles(debug.fake_grad)\n",
    "PrintLossGrad().on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualise()\n",
    "plot_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mogan.fit_generator(grid_generator(), samples_per_epoch=epoch_size, nb_epoch=250, \n",
    "                    verbose=1, callbacks=[VisualiseCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
